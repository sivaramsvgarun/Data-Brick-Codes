{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b84c272-49ed-400c-be2a-510d0333a06e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---------- Config ----------\n",
    "names = [\"Alice Sharma\", \"Rohan Singh\", \"Meera Nair\", \"Vikram Rao\", \n",
    "         \"Sneha Kapoor\", \"Arjun Mehta\", \"Pooja Reddy\", \"Kiran Das\", \"Raj Malhotra\", \"Neha Jain\"]\n",
    "\n",
    "regions = [\"North\", \"South\", \"East\", \"West\"]\n",
    "\n",
    "# Dictionary to maintain unique mapping\n",
    "customer_map = {}\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random datetime between two datetime objects.\"\"\"\n",
    "    return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
    "\n",
    "def generate_records(n=10):\n",
    "    records = []\n",
    "    next_id = 1  # incremental ID assignment\n",
    "    \n",
    "    for _ in range(n):\n",
    "        name = random.choice(names)\n",
    "        email = name.lower().replace(\" \", \".\") + \"@example.com\"\n",
    "        region = random.choice(regions)\n",
    "\n",
    "        # check if this combo exists\n",
    "        key = (name, region, email)\n",
    "        if key in customer_map:\n",
    "            customer_id = customer_map[key]\n",
    "        else:\n",
    "            customer_id = f\"CUST{str(next_id).zfill(3)}\"\n",
    "            customer_map[key] = customer_id\n",
    "            next_id += 1\n",
    "\n",
    "        effective_date = random_date(datetime(2023, 1, 1), datetime(2024, 1, 1))\n",
    "        effective_str = effective_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        action = random.choice([\"insert\", \"update\", \"delete\"])\n",
    "\n",
    "        if action == \"delete\":\n",
    "            end_date = (effective_date + timedelta(days=random.randint(30, 365))).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        else:\n",
    "            end_date = None\n",
    "\n",
    "        record = {\n",
    "            \"customer_id\": customer_id,\n",
    "            \"customer_name\": name,\n",
    "            \"email\": email,\n",
    "            \"region\": region,\n",
    "            \"effective_date\": effective_str,\n",
    "            \"end_date\": end_date\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "        # If update, create another version of the same record\n",
    "        if action == \"update\":\n",
    "            new_name = random.choice(names)\n",
    "            new_email = new_name.lower().replace(\" \", \".\") + \"@newmail.com\"\n",
    "            new_region = random.choice(regions)\n",
    "            new_effective_date = (effective_date + timedelta(days=random.randint(30, 300))).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "            new_key = (new_name, new_region, new_email)\n",
    "            if new_key in customer_map:\n",
    "                new_customer_id = customer_map[new_key]\n",
    "            else:\n",
    "                new_customer_id = f\"CUST{str(next_id).zfill(3)}\"\n",
    "                customer_map[new_key] = new_customer_id\n",
    "                next_id += 1\n",
    "\n",
    "            update_record = {\n",
    "                \"customer_id\": new_customer_id,\n",
    "                \"customer_name\": new_name,\n",
    "                \"email\": new_email,\n",
    "                \"region\": new_region,\n",
    "                \"effective_date\": new_effective_date,\n",
    "                \"end_date\": None\n",
    "            }\n",
    "            records.append(update_record)\n",
    "\n",
    "    return records\n",
    "\n",
    "def upload_to_s3(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.show(truncate=False)\n",
    "\n",
    "    now = datetime.now()\n",
    "    year = now.strftime(\"%Y\")\n",
    "    month = now.strftime(\"%m\")\n",
    "    day = now.strftime(\"%d\")\n",
    "    file_time = now.strftime(\"%H-%M-%S\")\n",
    "\n",
    "    base_path = \"s3://siva-databricks-files/cyber\"\n",
    "    output_path = f\"{base_path}/{year}/{month}/{day}/file_{file_time}.csv\"\n",
    "\n",
    "    (spark_df\n",
    "        .coalesce(1)\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .csv(output_path))\n",
    "\n",
    "    print(f\"âœ… File uploaded to {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = generate_records(7)  # generate 7 customers\n",
    "    upload_to_s3(data)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "s3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
